# ğŸ“¤ ì—…ë¡œë“œ & ìµœì  ì‹œê°„ ì‹œìŠ¤í…œ ìƒì„¸ ì„¤ê³„

## 1. ê°œìš”

### 1.1 ëª©í‘œ
- YouTube API í†µí•œ ìë™ ì—…ë¡œë“œ
- ì±„ë„ë³„ ìµœì  ì—…ë¡œë“œ ì‹œê°„ ë¶„ì„ ë° ì ìš©
- ë©”íƒ€ë°ì´í„° (ì œëª©, ì„¤ëª…, íƒœê·¸) ìë™ ìƒì„±
- ë©€í‹° í”Œë«í¼ í™•ì¥ ëŒ€ë¹„ (TikTok, Reels)

### 1.2 íŒŒì´í”„ë¼ì¸ íë¦„
```
ì˜ìƒ ì™„ì„± â†’ ë©”íƒ€ë°ì´í„° ìƒì„± â†’ ìµœì  ì‹œê°„ ê³„ì‚° â†’ ìŠ¤ì¼€ì¤„ë§ â†’ ì—…ë¡œë“œ â†’ ì„±ê³¼ ì¶”ì 
```

---

## 2. YouTube API ì—°ë™

### 2.1 ì¸ì¦ ì„¤ì •
```python
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
from pathlib import Path
import pickle


class YouTubeAuth:
    """YouTube API ì¸ì¦ ê´€ë¦¬"""
    
    SCOPES = [
        "https://www.googleapis.com/auth/youtube.upload",
        "https://www.googleapis.com/auth/youtube",
        "https://www.googleapis.com/auth/youtube.readonly",
        "https://www.googleapis.com/auth/yt-analytics.readonly",
    ]
    
    def __init__(
        self,
        client_secrets_file: Path,
        token_file: Path,
    ):
        self.client_secrets_file = client_secrets_file
        self.token_file = token_file
        self._credentials: Credentials | None = None
    
    def get_credentials(self) -> Credentials:
        """OAuth ì¸ì¦ ì •ë³´ íšë“"""
        if self._credentials and self._credentials.valid:
            return self._credentials
        
        # ì €ì¥ëœ í† í° í™•ì¸
        if self.token_file.exists():
            with open(self.token_file, "rb") as f:
                self._credentials = pickle.load(f)
        
        # í† í° ê°±ì‹  ë˜ëŠ” ìƒˆ ì¸ì¦
        if not self._credentials or not self._credentials.valid:
            if self._credentials and self._credentials.expired and self._credentials.refresh_token:
                self._credentials.refresh(Request())
            else:
                flow = InstalledAppFlow.from_client_secrets_file(
                    str(self.client_secrets_file),
                    self.SCOPES,
                )
                self._credentials = flow.run_local_server(port=0)
            
            # í† í° ì €ì¥
            with open(self.token_file, "wb") as f:
                pickle.dump(self._credentials, f)
        
        return self._credentials
    
    def get_youtube_service(self):
        """YouTube Data API ì„œë¹„ìŠ¤ ê°ì²´"""
        return build("youtube", "v3", credentials=self.get_credentials())
    
    def get_analytics_service(self):
        """YouTube Analytics API ì„œë¹„ìŠ¤ ê°ì²´"""
        return build("youtubeAnalytics", "v2", credentials=self.get_credentials())
```

### 2.2 ì—…ë¡œë“œ ì„œë¹„ìŠ¤
```python
from pydantic import BaseModel
from enum import Enum
from datetime import datetime
from typing import Optional
import httplib2


class PrivacyStatus(str, Enum):
    PUBLIC = "public"
    PRIVATE = "private"
    UNLISTED = "unlisted"


class VideoCategory(str, Enum):
    """YouTube ì¹´í…Œê³ ë¦¬ ID"""
    FILM = "1"
    AUTOS = "2"
    MUSIC = "10"
    PETS = "15"
    SPORTS = "17"
    GAMING = "20"
    PEOPLE_BLOGS = "22"
    COMEDY = "23"
    ENTERTAINMENT = "24"
    NEWS = "25"
    HOWTO_STYLE = "26"
    EDUCATION = "27"
    SCIENCE_TECH = "28"
    NONPROFITS = "29"


class UploadMetadata(BaseModel):
    """ì—…ë¡œë“œ ë©”íƒ€ë°ì´í„°"""
    title: str
    description: str
    tags: list[str]
    category_id: str = VideoCategory.SCIENCE_TECH
    
    # ê³µê°œ ì„¤ì •
    privacy_status: PrivacyStatus = PrivacyStatus.PRIVATE
    
    # ì˜ˆì•½ ì—…ë¡œë“œ
    scheduled_at: datetime | None = None
    
    # Shorts ê´€ë ¨
    is_shorts: bool = True
    
    # ì¶”ê°€ ì„¤ì •
    made_for_kids: bool = False
    default_language: str = "ko"
    
    # ì¸ë„¤ì¼
    thumbnail_path: Path | None = None


class UploadResult(BaseModel):
    """ì—…ë¡œë“œ ê²°ê³¼"""
    video_id: str
    youtube_url: str
    status: str
    uploaded_at: datetime
    scheduled_at: datetime | None = None


class YouTubeUploader:
    """YouTube ì—…ë¡œë“œ ì„œë¹„ìŠ¤"""
    
    MAX_RETRIES = 3
    
    def __init__(self, auth: YouTubeAuth):
        self.auth = auth
        self.youtube = auth.get_youtube_service()
    
    async def upload(
        self,
        video_path: Path,
        metadata: UploadMetadata,
    ) -> UploadResult:
        """ì˜ìƒ ì—…ë¡œë“œ"""
        
        # ìš”ì²­ ë°”ë”” êµ¬ì„±
        body = {
            "snippet": {
                "title": metadata.title[:100],  # ìµœëŒ€ 100ì
                "description": metadata.description[:5000],  # ìµœëŒ€ 5000ì
                "tags": metadata.tags[:500],  # ìµœëŒ€ 500ê°œ
                "categoryId": metadata.category_id,
                "defaultLanguage": metadata.default_language,
            },
            "status": {
                "privacyStatus": metadata.privacy_status,
                "selfDeclaredMadeForKids": metadata.made_for_kids,
            },
        }
        
        # ì˜ˆì•½ ì—…ë¡œë“œ
        if metadata.scheduled_at and metadata.privacy_status == PrivacyStatus.PRIVATE:
            body["status"]["privacyStatus"] = "private"
            body["status"]["publishAt"] = metadata.scheduled_at.isoformat() + "Z"
        
        # ë¯¸ë””ì–´ íŒŒì¼
        media = MediaFileUpload(
            str(video_path),
            mimetype="video/mp4",
            resumable=True,
            chunksize=1024 * 1024,  # 1MB ì²­í¬
        )
        
        # ì—…ë¡œë“œ ìš”ì²­
        request = self.youtube.videos().insert(
            part="snippet,status",
            body=body,
            media_body=media,
        )
        
        # ì¬ê°œ ê°€ëŠ¥í•œ ì—…ë¡œë“œ ì‹¤í–‰
        response = await self._resumable_upload(request)
        
        # ì¸ë„¤ì¼ ì—…ë¡œë“œ
        if metadata.thumbnail_path:
            await self._upload_thumbnail(response["id"], metadata.thumbnail_path)
        
        return UploadResult(
            video_id=response["id"],
            youtube_url=f"https://youtube.com/shorts/{response['id']}" if metadata.is_shorts 
                        else f"https://youtube.com/watch?v={response['id']}",
            status=response["status"]["uploadStatus"],
            uploaded_at=datetime.utcnow(),
            scheduled_at=metadata.scheduled_at,
        )
    
    async def _resumable_upload(self, request) -> dict:
        """ì¬ê°œ ê°€ëŠ¥í•œ ì—…ë¡œë“œ (ì²­í¬ ë‹¨ìœ„)"""
        response = None
        error = None
        retry = 0
        
        while response is None:
            try:
                status, response = request.next_chunk()
                if status:
                    print(f"Upload progress: {int(status.progress() * 100)}%")
            except httplib2.HttpLib2Error as e:
                error = e
                if retry < self.MAX_RETRIES:
                    retry += 1
                    print(f"Retry {retry}/{self.MAX_RETRIES}")
                    continue
                raise
        
        return response
    
    async def _upload_thumbnail(self, video_id: str, thumbnail_path: Path):
        """ì¸ë„¤ì¼ ì—…ë¡œë“œ"""
        media = MediaFileUpload(str(thumbnail_path), mimetype="image/jpeg")
        
        self.youtube.thumbnails().set(
            videoId=video_id,
            media_body=media,
        ).execute()
    
    async def update_metadata(
        self,
        video_id: str,
        metadata: UploadMetadata,
    ):
        """ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸"""
        body = {
            "id": video_id,
            "snippet": {
                "title": metadata.title,
                "description": metadata.description,
                "tags": metadata.tags,
                "categoryId": metadata.category_id,
            },
        }
        
        self.youtube.videos().update(
            part="snippet",
            body=body,
        ).execute()
    
    async def set_publish_time(
        self,
        video_id: str,
        publish_at: datetime,
    ):
        """ê³µê°œ ì˜ˆì•½ ì‹œê°„ ì„¤ì •"""
        body = {
            "id": video_id,
            "status": {
                "privacyStatus": "private",
                "publishAt": publish_at.isoformat() + "Z",
            },
        }
        
        self.youtube.videos().update(
            part="status",
            body=body,
        ).execute()
```

---

## 3. ë©”íƒ€ë°ì´í„° ìë™ ìƒì„±

### 3.1 ë©”íƒ€ë°ì´í„° ìƒì„±ê¸°
```python
from pydantic import BaseModel


class MetadataGeneratorConfig(BaseModel):
    """ë©”íƒ€ë°ì´í„° ìƒì„± ì„¤ì •"""
    
    # ì œëª©
    max_title_length: int = 70       # í´ë¦­ ìœ ë„ ìœ„í•´ ì§§ê²Œ
    include_emoji: bool = True
    title_style: str = "hook"        # hook, question, statement
    
    # ì„¤ëª…
    max_description_length: int = 500
    include_timestamps: bool = False  # ShortsëŠ” ë¶ˆí•„ìš”
    include_hashtags: bool = True
    
    # íƒœê·¸
    max_tags: int = 30
    include_trending_tags: bool = True
    
    # ì±„ë„ ê³ ì • ì •ë³´
    channel_hashtags: list[str] = []
    channel_links: list[str] = []


class MetadataGenerator:
    """LLM ê¸°ë°˜ ë©”íƒ€ë°ì´í„° ìƒì„±"""
    
    def __init__(
        self, 
        llm_client,
        config: MetadataGeneratorConfig | None = None,
    ):
        self.llm = llm_client
        self.config = config or MetadataGeneratorConfig()
    
    async def generate(
        self,
        script: str,
        topic: dict,
        channel_info: dict,
    ) -> UploadMetadata:
        """ë©”íƒ€ë°ì´í„° ìë™ ìƒì„±"""
        
        # 1. ì œëª© ìƒì„±
        title = await self._generate_title(script, topic)
        
        # 2. ì„¤ëª… ìƒì„±
        description = await self._generate_description(script, topic, channel_info)
        
        # 3. íƒœê·¸ ìƒì„±
        tags = await self._generate_tags(script, topic)
        
        return UploadMetadata(
            title=title,
            description=description,
            tags=tags,
            is_shorts=True,
        )
    
    async def _generate_title(self, script: str, topic: dict) -> str:
        """í´ë¦­ ìœ ë„ ì œëª© ìƒì„±"""
        prompt = f"""YouTube Shorts ì œëª©ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

ìŠ¤í¬ë¦½íŠ¸:
{script[:500]}

ì£¼ì œ: {topic.get('title', '')}
í‚¤ì›Œë“œ: {', '.join(topic.get('keywords', []))}

ìš”êµ¬ì‚¬í•­:
- ìµœëŒ€ {self.config.max_title_length}ì
- í˜¸ê¸°ì‹¬ ìœ ë°œ, í´ë¦­ ìœ ë„
- ê³¼ì¥ ì—†ì´ í•µì‹¬ë§Œ
- ì´ëª¨ì§€ {'1-2ê°œ í¬í•¨' if self.config.include_emoji else 'ë¯¸í¬í•¨'}
- ìŠ¤íƒ€ì¼: {self.config.title_style}

ì œëª©ë§Œ ì¶œë ¥:"""

        response = await self.llm.complete(prompt)
        return response.strip()[:self.config.max_title_length]
    
    async def _generate_description(
        self, 
        script: str, 
        topic: dict,
        channel_info: dict,
    ) -> str:
        """ì„¤ëª… ìƒì„±"""
        prompt = f"""YouTube Shorts ì„¤ëª…ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

ìŠ¤í¬ë¦½íŠ¸:
{script[:500]}

ì£¼ì œ: {topic.get('title', '')}

ìš”êµ¬ì‚¬í•­:
- ìµœëŒ€ {self.config.max_description_length}ì
- ì²« 2ì¤„ì´ ê°€ì¥ ì¤‘ìš” (ë¯¸ë¦¬ë³´ê¸°ì— í‘œì‹œë¨)
- í•µì‹¬ ë‚´ìš© ìš”ì•½
- í•´ì‹œíƒœê·¸ 3-5ê°œ í¬í•¨

ì„¤ëª…ë§Œ ì¶œë ¥:"""

        description = await self.llm.complete(prompt)
        
        # ì±„ë„ ê³ ì • ì •ë³´ ì¶”ê°€
        if self.config.channel_hashtags:
            hashtags = " ".join(f"#{tag}" for tag in self.config.channel_hashtags)
            description += f"\n\n{hashtags}"
        
        if self.config.channel_links:
            description += "\n\n" + "\n".join(self.config.channel_links)
        
        return description[:5000]
    
    async def _generate_tags(self, script: str, topic: dict) -> list[str]:
        """íƒœê·¸ ìƒì„±"""
        # ê¸°ë³¸ íƒœê·¸: ì£¼ì œ í‚¤ì›Œë“œ
        tags = list(topic.get('keywords', []))[:10]
        
        # LLMìœ¼ë¡œ ì¶”ê°€ íƒœê·¸ ìƒì„±
        prompt = f"""YouTube ê²€ìƒ‰ ìµœì í™”ë¥¼ ìœ„í•œ íƒœê·¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

ì£¼ì œ: {topic.get('title', '')}
í‚¤ì›Œë“œ: {', '.join(topic.get('keywords', []))}

ìš”êµ¬ì‚¬í•­:
- ê´€ë ¨ ê²€ìƒ‰ì–´ 15ê°œ
- í•œêµ­ì–´ + ì˜ì–´ í˜¼í•©
- êµ¬ì²´ì ì¸ ê²ƒë¶€í„° ì¼ë°˜ì ì¸ ê²ƒ ìˆœì„œ
- ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ì¶œë ¥

íƒœê·¸ë§Œ ì¶œë ¥:"""

        response = await self.llm.complete(prompt)
        additional_tags = [t.strip() for t in response.split(",")]
        
        tags.extend(additional_tags)
        
        # ì¤‘ë³µ ì œê±° + ê°œìˆ˜ ì œí•œ
        seen = set()
        unique_tags = []
        for tag in tags:
            if tag.lower() not in seen and tag:
                seen.add(tag.lower())
                unique_tags.append(tag)
        
        return unique_tags[:self.config.max_tags]
```

---

## 4. ìµœì  ì—…ë¡œë“œ ì‹œê°„ ë¶„ì„

### 4.1 ì‹œê°„ ë¶„ì„ ìŠ¤í‚¤ë§ˆ
```python
from pydantic import BaseModel
from datetime import datetime, time
from enum import Enum


class TimeSlot(BaseModel):
    """ì‹œê°„ëŒ€ ìŠ¬ë¡¯"""
    hour: int                    # 0-23
    day_of_week: int | None = None  # 0=ì›”, 6=ì¼ (Noneì´ë©´ ëª¨ë“  ìš”ì¼)
    
    # ì„±ê³¼ ì§€í‘œ
    avg_views: float = 0
    avg_engagement: float = 0
    sample_count: int = 0
    
    # ì ìˆ˜ (ì •ê·œí™”)
    score: float = 0


class TimeAnalysisResult(BaseModel):
    """ì‹œê°„ ë¶„ì„ ê²°ê³¼"""
    channel_id: str
    analyzed_at: datetime
    
    # ìµœì  ì‹œê°„ (ìˆœìœ„ë³„)
    best_slots: list[TimeSlot]
    
    # í”¼í•´ì•¼ í•  ì‹œê°„
    worst_slots: list[TimeSlot]
    
    # ìš”ì¼ë³„ ìµœì  ì‹œê°„
    best_by_day: dict[int, list[TimeSlot]]  # day -> slots
    
    # ë¶„ì„ ê¸°ê°„
    data_from: datetime
    data_to: datetime
    total_videos_analyzed: int


class SchedulePreference(BaseModel):
    """ì—…ë¡œë“œ ìŠ¤ì¼€ì¤„ ì„ í˜¸ ì„¤ì •"""
    
    # í—ˆìš© ì‹œê°„ëŒ€
    allowed_hours: list[int] = list(range(6, 24))  # 6ì‹œ-23ì‹œ
    
    # ì„ í˜¸ ìš”ì¼ (Noneì´ë©´ ëª¨ë“  ìš”ì¼)
    preferred_days: list[int] | None = None
    
    # ìµœì†Œ ê°„ê²© (ê°™ì€ ì±„ë„ ì˜ìƒ ê°„)
    min_interval_hours: int = 4
    
    # ìµœëŒ€ ì¼ì¼ ì—…ë¡œë“œ
    max_daily_uploads: int = 3
    
    # í”¼í¬ ì‹œê°„ ê°€ì¤‘ì¹˜
    peak_hour_weight: float = 1.5
```

### 4.2 YouTube Analytics ìˆ˜ì§‘ê¸°
```python
from datetime import datetime, timedelta


class YouTubeAnalyticsCollector:
    """YouTube Analytics ë°ì´í„° ìˆ˜ì§‘"""
    
    def __init__(self, auth: YouTubeAuth):
        self.analytics = auth.get_analytics_service()
        self.youtube = auth.get_youtube_service()
    
    async def get_video_performance(
        self,
        channel_id: str,
        days: int = 90,
    ) -> list[dict]:
        """ì±„ë„ ì˜ìƒë³„ ì„±ê³¼ ë°ì´í„°"""
        end_date = datetime.utcnow().date()
        start_date = end_date - timedelta(days=days)
        
        # ì±„ë„ ì˜ìƒ ëª©ë¡ ì¡°íšŒ
        videos = await self._get_channel_videos(channel_id)
        
        performance_data = []
        
        for video in videos:
            video_id = video["id"]
            published_at = datetime.fromisoformat(
                video["snippet"]["publishedAt"].replace("Z", "+00:00")
            )
            
            # Analytics ë°ì´í„° ì¡°íšŒ
            response = self.analytics.reports().query(
                ids=f"channel=={channel_id}",
                startDate=start_date.isoformat(),
                endDate=end_date.isoformat(),
                metrics="views,likes,comments,averageViewDuration,averageViewPercentage",
                dimensions="video",
                filters=f"video=={video_id}",
            ).execute()
            
            if response.get("rows"):
                row = response["rows"][0]
                performance_data.append({
                    "video_id": video_id,
                    "published_at": published_at,
                    "published_hour": published_at.hour,
                    "published_day": published_at.weekday(),
                    "views": row[1],
                    "likes": row[2],
                    "comments": row[3],
                    "avg_view_duration": row[4],
                    "avg_view_percentage": row[5],
                    "engagement_rate": (row[2] + row[3]) / max(row[1], 1),
                })
        
        return performance_data
    
    async def _get_channel_videos(self, channel_id: str) -> list[dict]:
        """ì±„ë„ì˜ ëª¨ë“  ì˜ìƒ ì¡°íšŒ"""
        videos = []
        next_page_token = None
        
        while True:
            response = self.youtube.search().list(
                channelId=channel_id,
                part="id,snippet",
                type="video",
                maxResults=50,
                pageToken=next_page_token,
            ).execute()
            
            videos.extend(response.get("items", []))
            
            next_page_token = response.get("nextPageToken")
            if not next_page_token:
                break
        
        return videos
    
    async def get_audience_retention(
        self,
        channel_id: str,
        days: int = 28,
    ) -> dict:
        """ì‹œì²­ì í™œë™ ì‹œê°„ëŒ€ ë¶„ì„"""
        end_date = datetime.utcnow().date()
        start_date = end_date - timedelta(days=days)
        
        response = self.analytics.reports().query(
            ids=f"channel=={channel_id}",
            startDate=start_date.isoformat(),
            endDate=end_date.isoformat(),
            metrics="views",
            dimensions="day,hour",  # ìš”ì¼ + ì‹œê°„
        ).execute()
        
        # ì‹œê°„ëŒ€ë³„ ì§‘ê³„
        hourly_views = {}
        for row in response.get("rows", []):
            day = int(row[0])  # ìš”ì¼
            hour = int(row[1])  # ì‹œê°„
            views = row[2]
            
            key = (day, hour)
            hourly_views[key] = hourly_views.get(key, 0) + views
        
        return hourly_views
```

### 4.3 ìµœì  ì‹œê°„ ë¶„ì„ê¸°
```python
import numpy as np


class OptimalTimeAnalyzer:
    """ìµœì  ì—…ë¡œë“œ ì‹œê°„ ë¶„ì„"""
    
    def __init__(self, analytics_collector: YouTubeAnalyticsCollector):
        self.collector = analytics_collector
    
    async def analyze(
        self,
        channel_id: str,
        days: int = 90,
    ) -> TimeAnalysisResult:
        """ì±„ë„ ìµœì  ì—…ë¡œë“œ ì‹œê°„ ë¶„ì„"""
        
        # 1. ì˜ìƒ ì„±ê³¼ ë°ì´í„° ìˆ˜ì§‘
        performance_data = await self.collector.get_video_performance(channel_id, days)
        
        # 2. ì‹œì²­ì í™œë™ ì‹œê°„ëŒ€ ìˆ˜ì§‘
        audience_activity = await self.collector.get_audience_retention(channel_id)
        
        # 3. ì‹œê°„ëŒ€ë³„ ì§‘ê³„
        time_slots = self._aggregate_by_time(performance_data)
        
        # 4. ì‹œì²­ì í™œë™ ë°˜ì˜ (ê°€ì¤‘ì¹˜)
        time_slots = self._apply_audience_weight(time_slots, audience_activity)
        
        # 5. ì ìˆ˜ ê³„ì‚° ë° ì •ê·œí™”
        time_slots = self._calculate_scores(time_slots)
        
        # 6. ê²°ê³¼ ì •ë¦¬
        sorted_slots = sorted(time_slots, key=lambda x: x.score, reverse=True)
        
        return TimeAnalysisResult(
            channel_id=channel_id,
            analyzed_at=datetime.utcnow(),
            best_slots=sorted_slots[:10],
            worst_slots=sorted_slots[-5:],
            best_by_day=self._group_by_day(sorted_slots),
            data_from=datetime.utcnow() - timedelta(days=days),
            data_to=datetime.utcnow(),
            total_videos_analyzed=len(performance_data),
        )
    
    def _aggregate_by_time(self, data: list[dict]) -> list[TimeSlot]:
        """ì‹œê°„ëŒ€ë³„ ì§‘ê³„"""
        slots = {}
        
        for item in data:
            key = (item["published_hour"], item["published_day"])
            
            if key not in slots:
                slots[key] = {
                    "hour": item["published_hour"],
                    "day_of_week": item["published_day"],
                    "views": [],
                    "engagements": [],
                }
            
            slots[key]["views"].append(item["views"])
            slots[key]["engagements"].append(item["engagement_rate"])
        
        return [
            TimeSlot(
                hour=v["hour"],
                day_of_week=v["day_of_week"],
                avg_views=np.mean(v["views"]) if v["views"] else 0,
                avg_engagement=np.mean(v["engagements"]) if v["engagements"] else 0,
                sample_count=len(v["views"]),
            )
            for v in slots.values()
        ]
    
    def _apply_audience_weight(
        self,
        slots: list[TimeSlot],
        audience_activity: dict,
    ) -> list[TimeSlot]:
        """ì‹œì²­ì í™œë™ ì‹œê°„ëŒ€ ê°€ì¤‘ì¹˜ ì ìš©"""
        if not audience_activity:
            return slots
        
        max_activity = max(audience_activity.values()) if audience_activity else 1
        
        for slot in slots:
            key = (slot.day_of_week, slot.hour)
            activity = audience_activity.get(key, 0)
            
            # ì‹œì²­ì í™œë™ì´ ë§ì€ ì‹œê°„ëŒ€ì— ê°€ì¤‘ì¹˜
            activity_weight = 1 + (activity / max_activity) * 0.5
            slot.avg_views *= activity_weight
        
        return slots
    
    def _calculate_scores(self, slots: list[TimeSlot]) -> list[TimeSlot]:
        """ì ìˆ˜ ê³„ì‚° ë° ì •ê·œí™”"""
        if not slots:
            return slots
        
        # Min-Max ì •ê·œí™”
        max_views = max(s.avg_views for s in slots) or 1
        max_engagement = max(s.avg_engagement for s in slots) or 1
        
        for slot in slots:
            view_score = slot.avg_views / max_views
            engagement_score = slot.avg_engagement / max_engagement
            
            # ìƒ˜í”Œ ìˆ˜ì— ë”°ë¥¸ ì‹ ë¢°ë„ ê°€ì¤‘ì¹˜
            confidence = min(slot.sample_count / 10, 1.0)
            
            # ì¢…í•© ì ìˆ˜ (views 60%, engagement 40%)
            slot.score = (view_score * 0.6 + engagement_score * 0.4) * confidence
        
        return slots
    
    def _group_by_day(self, slots: list[TimeSlot]) -> dict[int, list[TimeSlot]]:
        """ìš”ì¼ë³„ ê·¸ë£¹í™”"""
        by_day = {}
        for slot in slots:
            day = slot.day_of_week
            if day not in by_day:
                by_day[day] = []
            by_day[day].append(slot)
        
        # ê° ìš”ì¼ë³„ë¡œ ì ìˆ˜ìˆœ ì •ë ¬
        for day in by_day:
            by_day[day] = sorted(by_day[day], key=lambda x: x.score, reverse=True)[:3]
        
        return by_day
```

### 4.4 ìŠ¤ì¼€ì¤„ëŸ¬
```python
from datetime import datetime, timedelta
import heapq


class UploadScheduler:
    """ì—…ë¡œë“œ ìŠ¤ì¼€ì¤„ ê´€ë¦¬"""
    
    def __init__(
        self,
        time_analyzer: OptimalTimeAnalyzer,
        preference: SchedulePreference | None = None,
    ):
        self.analyzer = time_analyzer
        self.preference = preference or SchedulePreference()
        
        # ì±„ë„ë³„ ë¶„ì„ ìºì‹œ
        self._analysis_cache: dict[str, TimeAnalysisResult] = {}
        
        # ìŠ¤ì¼€ì¤„ í (í™)
        self._schedule_queue: list[tuple[datetime, str, str]] = []  # (time, channel_id, video_id)
    
    async def get_next_optimal_time(
        self,
        channel_id: str,
        after: datetime | None = None,
    ) -> datetime:
        """ë‹¤ìŒ ìµœì  ì—…ë¡œë“œ ì‹œê°„ ê³„ì‚°"""
        after = after or datetime.utcnow()
        
        # ë¶„ì„ ê²°ê³¼ ìºì‹œ ë˜ëŠ” ìƒˆë¡œ ë¶„ì„
        if channel_id not in self._analysis_cache:
            self._analysis_cache[channel_id] = await self.analyzer.analyze(channel_id)
        
        analysis = self._analysis_cache[channel_id]
        
        # ìµœê·¼ ì—…ë¡œë“œ ì‹œê°„ í™•ì¸ (ìµœì†Œ ê°„ê²© ì²´í¬)
        last_upload = await self._get_last_upload_time(channel_id)
        if last_upload:
            min_next = last_upload + timedelta(hours=self.preference.min_interval_hours)
            after = max(after, min_next)
        
        # ì¼ì¼ ì—…ë¡œë“œ ì œí•œ ì²´í¬
        today_count = await self._get_today_upload_count(channel_id)
        if today_count >= self.preference.max_daily_uploads:
            # ë‚´ì¼ë¡œ ë„˜ê¸°ê¸°
            after = datetime(after.year, after.month, after.day) + timedelta(days=1, hours=6)
        
        # ìµœì  ì‹œê°„ ì°¾ê¸°
        best_time = self._find_next_best_time(analysis, after)
        
        return best_time
    
    def _find_next_best_time(
        self,
        analysis: TimeAnalysisResult,
        after: datetime,
    ) -> datetime:
        """after ì´í›„ ê°€ì¥ ì¢‹ì€ ì‹œê°„ ì°¾ê¸°"""
        candidates = []
        
        # í–¥í›„ 7ì¼ ë‚´ í›„ë³´ ì‹œê°„ ìƒì„±
        for days_ahead in range(7):
            target_date = after.date() + timedelta(days=days_ahead)
            target_day = target_date.weekday()
            
            # ì„ í˜¸ ìš”ì¼ ì²´í¬
            if self.preference.preferred_days and target_day not in self.preference.preferred_days:
                continue
            
            # í•´ë‹¹ ìš”ì¼ì˜ ìµœì  ì‹œê°„ëŒ€
            day_slots = analysis.best_by_day.get(target_day, analysis.best_slots[:3])
            
            for slot in day_slots:
                if slot.hour not in self.preference.allowed_hours:
                    continue
                
                candidate = datetime(
                    target_date.year,
                    target_date.month,
                    target_date.day,
                    slot.hour,
                    0,  # ì •ì‹œ
                )
                
                if candidate > after:
                    candidates.append((candidate, slot.score))
        
        if not candidates:
            # í´ë°±: ë‹¤ìŒë‚  ì˜¤ì „ 9ì‹œ
            return datetime(after.year, after.month, after.day, 9, 0) + timedelta(days=1)
        
        # ì ìˆ˜ ë†’ì€ ìˆœ + ë¹ ë¥¸ ì‹œê°„ ìˆœìœ¼ë¡œ ì •ë ¬
        candidates.sort(key=lambda x: (-x[1], x[0]))
        
        return candidates[0][0]
    
    async def schedule_upload(
        self,
        channel_id: str,
        video_id: str,
        preferred_time: datetime | None = None,
    ) -> datetime:
        """ì—…ë¡œë“œ ìŠ¤ì¼€ì¤„ ë“±ë¡"""
        if preferred_time:
            scheduled_time = preferred_time
        else:
            scheduled_time = await self.get_next_optimal_time(channel_id)
        
        heapq.heappush(
            self._schedule_queue,
            (scheduled_time, channel_id, video_id)
        )
        
        return scheduled_time
    
    async def get_pending_uploads(self) -> list[tuple[datetime, str, str]]:
        """ëŒ€ê¸° ì¤‘ì¸ ì—…ë¡œë“œ ëª©ë¡"""
        return sorted(self._schedule_queue)
    
    async def _get_last_upload_time(self, channel_id: str) -> datetime | None:
        """ì±„ë„ì˜ ë§ˆì§€ë§‰ ì—…ë¡œë“œ ì‹œê°„"""
        # TODO: DBì—ì„œ ì¡°íšŒ
        return None
    
    async def _get_today_upload_count(self, channel_id: str) -> int:
        """ì˜¤ëŠ˜ ì—…ë¡œë“œ ìˆ˜"""
        # TODO: DBì—ì„œ ì¡°íšŒ
        return 0
```

---

## 5. ì—…ë¡œë“œ íŒŒì´í”„ë¼ì¸ í†µí•©

```python
class UploadPipeline:
    """ì—…ë¡œë“œ ì „ì²´ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(
        self,
        uploader: YouTubeUploader,
        metadata_generator: MetadataGenerator,
        scheduler: UploadScheduler,
    ):
        self.uploader = uploader
        self.metadata_gen = metadata_generator
        self.scheduler = scheduler
    
    async def process_upload(
        self,
        video_result: "VideoGenerationResult",
        script: "GeneratedScript",
        channel: "Channel",
        immediate: bool = False,
    ) -> UploadResult:
        """ì˜ìƒ â†’ ë©”íƒ€ë°ì´í„° ìƒì„± â†’ ìŠ¤ì¼€ì¤„ë§ â†’ ì—…ë¡œë“œ"""
        
        # 1. ë©”íƒ€ë°ì´í„° ìƒì„±
        metadata = await self.metadata_gen.generate(
            script=script.script,
            topic={
                "title": script.topic.title,
                "keywords": script.topic.keywords,
            },
            channel_info={
                "name": channel.name,
                "hashtags": channel.default_hashtags,
            },
        )
        
        # 2. ì—…ë¡œë“œ ì‹œê°„ ê²°ì •
        if immediate:
            metadata.privacy_status = PrivacyStatus.PUBLIC
            metadata.scheduled_at = None
        else:
            scheduled_time = await self.scheduler.get_next_optimal_time(channel.id)
            metadata.scheduled_at = scheduled_time
            metadata.privacy_status = PrivacyStatus.PRIVATE
        
        # 3. ì¸ë„¤ì¼ ì„¤ì •
        metadata.thumbnail_path = video_result.thumbnail_path
        
        # 4. ì—…ë¡œë“œ
        result = await self.uploader.upload(
            video_path=video_result.video_path,
            metadata=metadata,
        )
        
        # 5. ìŠ¤ì¼€ì¤„ ë“±ë¡ (ì¶”ì ìš©)
        await self.scheduler.schedule_upload(
            channel_id=channel.id,
            video_id=result.video_id,
            preferred_time=metadata.scheduled_at,
        )
        
        return result
```

---

## 6. ì´ˆê¸° ì„¤ì • (ë¶„ì„ ë°ì´í„° ì—†ì„ ë•Œ)

```python
class DefaultTimeSlots:
    """ë¶„ì„ ë°ì´í„° ì—†ì„ ë•Œ ê¸°ë³¸ ì‹œê°„ëŒ€"""
    
    # í•œêµ­ ì‹œê°„ ê¸°ì¤€ ì¼ë°˜ì ì¸ ê³¨ë“ íƒ€ì„
    KOREAN_GOLDEN_HOURS = {
        # í‰ì¼
        0: [7, 12, 18, 21],   # ì›”
        1: [7, 12, 18, 21],   # í™”
        2: [7, 12, 18, 21],   # ìˆ˜
        3: [7, 12, 18, 21],   # ëª©
        4: [7, 12, 18, 22],   # ê¸ˆ
        # ì£¼ë§
        5: [10, 14, 18, 21],  # í† 
        6: [10, 14, 18, 21],  # ì¼
    }
    
    # ì¹´í…Œê³ ë¦¬ë³„ ì¶”ì²œ ì‹œê°„
    CATEGORY_HOURS = {
        "tech": [9, 12, 18],           # ì§ì¥ì¸ ëŒ€ìƒ
        "entertainment": [12, 18, 21, 23],  # ì €ë…/ë°¤
        "education": [7, 9, 19],       # ì¶œí‡´ê·¼ + ì €ë…
        "gaming": [15, 18, 21, 23],    # ì˜¤í›„/ë°¤
        "lifestyle": [7, 10, 18],      # ì•„ì¹¨/ì €ë…
    }
    
    @classmethod
    def get_default_slots(
        cls, 
        category: str = "tech",
        timezone: str = "Asia/Seoul",
    ) -> list[TimeSlot]:
        """ê¸°ë³¸ ì¶”ì²œ ì‹œê°„ëŒ€"""
        hours = cls.CATEGORY_HOURS.get(category, cls.CATEGORY_HOURS["tech"])
        
        slots = []
        for day in range(7):
            for hour in hours:
                # ì£¼ë§ì€ ë‹¤ë¥¸ ì‹œê°„ëŒ€
                if day in [5, 6] and hour < 10:
                    continue
                    
                slots.append(TimeSlot(
                    hour=hour,
                    day_of_week=day,
                    score=0.8 if hour in cls.KOREAN_GOLDEN_HOURS.get(day, []) else 0.5,
                ))
        
        return sorted(slots, key=lambda x: x.score, reverse=True)
```

---

## 7. ê¸°ìˆ  ìŠ¤íƒ ì •ë¦¬

| ì»´í¬ë„ŒíŠ¸ | ë¼ì´ë¸ŒëŸ¬ë¦¬ | ë¹„ê³  |
|----------|------------|------|
| **YouTube API** | google-api-python-client | ì—…ë¡œë“œ, Analytics |
| **OAuth** | google-auth-oauthlib | ì¸ì¦ |
| **HTTP** | httpx | ë¹„ë™ê¸° ìš”ì²­ |
| **ìŠ¤ì¼€ì¤„ë§** | APScheduler | ì˜ˆì•½ ì—…ë¡œë“œ ì‹¤í–‰ |
| **ë¶„ì„** | numpy | í†µê³„ ê³„ì‚° |
